{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae066023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.9.0\n",
      "Torchvision Version:  0.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9abdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40610831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa769728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet34\":\n",
    "        \"\"\" Resnet34\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet50\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet101\":\n",
    "        \"\"\" Resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet152\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224    \n",
    "    \n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "#model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cea5715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n",
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlim/miniconda3/envs/wsod/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-pyrtjkcs/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4711 Acc: 0.8347\n",
      "val Loss: 0.2710 Acc: 0.9052\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.2535 Acc: 0.9139\n",
      "val Loss: 0.1781 Acc: 0.9404\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.1896 Acc: 0.9349\n",
      "val Loss: 0.1569 Acc: 0.9394\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.1511 Acc: 0.9494\n",
      "val Loss: 0.1735 Acc: 0.9394\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.1483 Acc: 0.9465\n",
      "val Loss: 0.0935 Acc: 0.9717\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.1182 Acc: 0.9586\n",
      "val Loss: 0.1326 Acc: 0.9589\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.1029 Acc: 0.9657\n",
      "val Loss: 0.1467 Acc: 0.9492\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.1068 Acc: 0.9606\n",
      "val Loss: 0.2015 Acc: 0.9277\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0906 Acc: 0.9678\n",
      "val Loss: 0.1121 Acc: 0.9648\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0890 Acc: 0.9686\n",
      "val Loss: 0.1722 Acc: 0.9413\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0808 Acc: 0.9727\n",
      "val Loss: 0.1838 Acc: 0.9374\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0851 Acc: 0.9700\n",
      "val Loss: 0.1226 Acc: 0.9648\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0716 Acc: 0.9755\n",
      "val Loss: 0.1032 Acc: 0.9658\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0608 Acc: 0.9790\n",
      "val Loss: 0.2151 Acc: 0.9326\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0678 Acc: 0.9751\n",
      "val Loss: 0.1175 Acc: 0.9638\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0664 Acc: 0.9782\n",
      "val Loss: 0.1248 Acc: 0.9638\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0509 Acc: 0.9822\n",
      "val Loss: 0.1394 Acc: 0.9501\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0527 Acc: 0.9814\n",
      "val Loss: 0.0919 Acc: 0.9707\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0545 Acc: 0.9829\n",
      "val Loss: 0.0765 Acc: 0.9765\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0578 Acc: 0.9794\n",
      "val Loss: 0.0781 Acc: 0.9775\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0515 Acc: 0.9825\n",
      "val Loss: 0.0920 Acc: 0.9677\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0515 Acc: 0.9829\n",
      "val Loss: 0.1120 Acc: 0.9677\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0514 Acc: 0.9820\n",
      "val Loss: 0.1150 Acc: 0.9629\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.9798\n",
      "val Loss: 0.1015 Acc: 0.9697\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0595 Acc: 0.9790\n",
      "val Loss: 0.1342 Acc: 0.9521\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0435 Acc: 0.9861\n",
      "val Loss: 0.1456 Acc: 0.9648\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0395 Acc: 0.9869\n",
      "val Loss: 0.0698 Acc: 0.9756\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0432 Acc: 0.9827\n",
      "val Loss: 0.0876 Acc: 0.9765\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0498 Acc: 0.9820\n",
      "val Loss: 0.0815 Acc: 0.9765\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0436 Acc: 0.9841\n",
      "val Loss: 0.0909 Acc: 0.9804\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.9849\n",
      "val Loss: 0.0592 Acc: 0.9844\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9904\n",
      "val Loss: 0.0934 Acc: 0.9717\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0420 Acc: 0.9851\n",
      "val Loss: 0.1007 Acc: 0.9717\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0352 Acc: 0.9884\n",
      "val Loss: 0.0731 Acc: 0.9785\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0374 Acc: 0.9867\n",
      "val Loss: 0.0683 Acc: 0.9726\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.0381 Acc: 0.9876\n",
      "val Loss: 0.1031 Acc: 0.9765\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0369 Acc: 0.9876\n",
      "val Loss: 0.0931 Acc: 0.9824\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0418 Acc: 0.9863\n",
      "val Loss: 0.0932 Acc: 0.9775\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.9880\n",
      "val Loss: 0.0604 Acc: 0.9834\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9888\n",
      "val Loss: 0.2932 Acc: 0.9277\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0337 Acc: 0.9906\n",
      "val Loss: 0.0675 Acc: 0.9814\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0411 Acc: 0.9855\n",
      "val Loss: 0.0548 Acc: 0.9844\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9876\n",
      "val Loss: 0.0516 Acc: 0.9892\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0348 Acc: 0.9878\n",
      "val Loss: 0.0596 Acc: 0.9814\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0351 Acc: 0.9882\n",
      "val Loss: 0.0511 Acc: 0.9922\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0349 Acc: 0.9884\n",
      "val Loss: 0.0609 Acc: 0.9863\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0223 Acc: 0.9916\n",
      "val Loss: 0.0576 Acc: 0.9844\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 0.9912\n",
      "val Loss: 0.1521 Acc: 0.9599\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0316 Acc: 0.9900\n",
      "val Loss: 0.0635 Acc: 0.9844\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0372 Acc: 0.9880\n",
      "val Loss: 0.1160 Acc: 0.9648\n",
      "\n",
      "Training complete in 10m 18s\n",
      "Best val Acc: 0.992180\n",
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.4548 Acc: 0.8396\n",
      "val Loss: 0.3663 Acc: 0.8847\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.2275 Acc: 0.9175\n",
      "val Loss: 0.1531 Acc: 0.9423\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.1945 Acc: 0.9331\n",
      "val Loss: 0.1732 Acc: 0.9374\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.1407 Acc: 0.9508\n",
      "val Loss: 0.1162 Acc: 0.9560\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.1494 Acc: 0.9469\n",
      "val Loss: 0.1237 Acc: 0.9531\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9622\n",
      "val Loss: 0.1277 Acc: 0.9570\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.1360 Acc: 0.9541\n",
      "val Loss: 0.0947 Acc: 0.9677\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.1086 Acc: 0.9622\n",
      "val Loss: 0.1438 Acc: 0.9550\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0914 Acc: 0.9692\n",
      "val Loss: 0.1429 Acc: 0.9541\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0819 Acc: 0.9714\n",
      "val Loss: 0.0885 Acc: 0.9717\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0783 Acc: 0.9741\n",
      "val Loss: 0.0751 Acc: 0.9726\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0765 Acc: 0.9716\n",
      "val Loss: 0.1463 Acc: 0.9501\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0771 Acc: 0.9712\n",
      "val Loss: 0.0795 Acc: 0.9697\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0732 Acc: 0.9741\n",
      "val Loss: 0.0744 Acc: 0.9736\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0724 Acc: 0.9767\n",
      "val Loss: 0.0940 Acc: 0.9756\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0681 Acc: 0.9767\n",
      "val Loss: 0.0886 Acc: 0.9726\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9780\n",
      "val Loss: 0.1610 Acc: 0.9638\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0633 Acc: 0.9771\n",
      "val Loss: 0.0632 Acc: 0.9824\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0503 Acc: 0.9824\n",
      "val Loss: 0.1165 Acc: 0.9609\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0557 Acc: 0.9804\n",
      "val Loss: 0.0998 Acc: 0.9765\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0624 Acc: 0.9778\n",
      "val Loss: 0.0701 Acc: 0.9795\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0515 Acc: 0.9818\n",
      "val Loss: 0.1432 Acc: 0.9668\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0490 Acc: 0.9825\n",
      "val Loss: 0.1252 Acc: 0.9619\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0508 Acc: 0.9837\n",
      "val Loss: 0.1638 Acc: 0.9629\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0625 Acc: 0.9786\n",
      "val Loss: 0.0580 Acc: 0.9834\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0409 Acc: 0.9849\n",
      "val Loss: 0.2100 Acc: 0.9394\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0477 Acc: 0.9839\n",
      "val Loss: 0.0552 Acc: 0.9844\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0634 Acc: 0.9798\n",
      "val Loss: 0.1376 Acc: 0.9677\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0400 Acc: 0.9869\n",
      "val Loss: 0.0669 Acc: 0.9844\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0528 Acc: 0.9820\n",
      "val Loss: 0.0896 Acc: 0.9726\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0436 Acc: 0.9845\n",
      "val Loss: 0.1164 Acc: 0.9648\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0448 Acc: 0.9851\n",
      "val Loss: 0.1037 Acc: 0.9765\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0611 Acc: 0.9790\n",
      "val Loss: 0.1074 Acc: 0.9707\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0427 Acc: 0.9849\n",
      "val Loss: 0.1003 Acc: 0.9677\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0435 Acc: 0.9863\n",
      "val Loss: 0.0727 Acc: 0.9765\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.0422 Acc: 0.9851\n",
      "val Loss: 0.0713 Acc: 0.9795\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0413 Acc: 0.9869\n",
      "val Loss: 0.1045 Acc: 0.9765\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.9890\n",
      "val Loss: 0.0754 Acc: 0.9814\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.9894\n",
      "val Loss: 0.0706 Acc: 0.9775\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0584 Acc: 0.9816\n",
      "val Loss: 0.1506 Acc: 0.9580\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0497 Acc: 0.9827\n",
      "val Loss: 0.0798 Acc: 0.9697\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0375 Acc: 0.9884\n",
      "val Loss: 0.0685 Acc: 0.9785\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0393 Acc: 0.9869\n",
      "val Loss: 0.0423 Acc: 0.9863\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0314 Acc: 0.9904\n",
      "val Loss: 0.0490 Acc: 0.9883\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.9880\n",
      "val Loss: 0.0769 Acc: 0.9726\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.9900\n",
      "val Loss: 0.0970 Acc: 0.9726\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 0.9894\n",
      "val Loss: 0.0669 Acc: 0.9824\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0457 Acc: 0.9845\n",
      "val Loss: 0.0777 Acc: 0.9795\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0413 Acc: 0.9867\n",
      "val Loss: 0.0920 Acc: 0.9795\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.9892\n",
      "val Loss: 0.0510 Acc: 0.9834\n",
      "\n",
      "Training complete in 16m 28s\n",
      "Best val Acc: 0.988270\n",
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.0.conv3.weight\n",
      "\t layer1.0.bn3.weight\n",
      "\t layer1.0.bn3.bias\n",
      "\t layer1.0.downsample.0.weight\n",
      "\t layer1.0.downsample.1.weight\n",
      "\t layer1.0.downsample.1.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.1.conv3.weight\n",
      "\t layer1.1.bn3.weight\n",
      "\t layer1.1.bn3.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer1.2.conv3.weight\n",
      "\t layer1.2.bn3.weight\n",
      "\t layer1.2.bn3.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.conv3.weight\n",
      "\t layer2.0.bn3.weight\n",
      "\t layer2.0.bn3.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.1.conv3.weight\n",
      "\t layer2.1.bn3.weight\n",
      "\t layer2.1.bn3.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.2.conv3.weight\n",
      "\t layer2.2.bn3.weight\n",
      "\t layer2.2.bn3.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer2.3.conv3.weight\n",
      "\t layer2.3.bn3.weight\n",
      "\t layer2.3.bn3.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.conv3.weight\n",
      "\t layer3.0.bn3.weight\n",
      "\t layer3.0.bn3.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.1.conv3.weight\n",
      "\t layer3.1.bn3.weight\n",
      "\t layer3.1.bn3.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.2.conv3.weight\n",
      "\t layer3.2.bn3.weight\n",
      "\t layer3.2.bn3.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.3.conv3.weight\n",
      "\t layer3.3.bn3.weight\n",
      "\t layer3.3.bn3.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.4.conv3.weight\n",
      "\t layer3.4.bn3.weight\n",
      "\t layer3.4.bn3.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer3.5.conv3.weight\n",
      "\t layer3.5.bn3.weight\n",
      "\t layer3.5.bn3.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.conv3.weight\n",
      "\t layer4.0.bn3.weight\n",
      "\t layer4.0.bn3.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.1.conv3.weight\n",
      "\t layer4.1.bn3.weight\n",
      "\t layer4.1.bn3.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t layer4.2.conv3.weight\n",
      "\t layer4.2.bn3.weight\n",
      "\t layer4.2.bn3.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.4345 Acc: 0.8461\n",
      "val Loss: 0.1980 Acc: 0.9267\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.2284 Acc: 0.9229\n",
      "val Loss: 0.0777 Acc: 0.9775\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.1826 Acc: 0.9355\n",
      "val Loss: 0.0834 Acc: 0.9726\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.1297 Acc: 0.9524\n",
      "val Loss: 0.1108 Acc: 0.9677\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.1291 Acc: 0.9573\n",
      "val Loss: 0.0959 Acc: 0.9717\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.1231 Acc: 0.9588\n",
      "val Loss: 0.1353 Acc: 0.9501\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9571\n",
      "val Loss: 0.0877 Acc: 0.9736\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.0874 Acc: 0.9725\n",
      "val Loss: 0.1059 Acc: 0.9629\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0879 Acc: 0.9702\n",
      "val Loss: 0.0694 Acc: 0.9765\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0729 Acc: 0.9761\n",
      "val Loss: 0.1126 Acc: 0.9677\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0794 Acc: 0.9716\n",
      "val Loss: 0.0990 Acc: 0.9677\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0906 Acc: 0.9690\n",
      "val Loss: 0.0791 Acc: 0.9736\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0863 Acc: 0.9694\n",
      "val Loss: 0.0780 Acc: 0.9765\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0926 Acc: 0.9684\n",
      "val Loss: 0.0804 Acc: 0.9765\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0689 Acc: 0.9753\n",
      "val Loss: 0.1404 Acc: 0.9531\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0660 Acc: 0.9778\n",
      "val Loss: 0.0613 Acc: 0.9804\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0557 Acc: 0.9824\n",
      "val Loss: 0.0592 Acc: 0.9853\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0575 Acc: 0.9778\n",
      "val Loss: 0.0940 Acc: 0.9746\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0600 Acc: 0.9822\n",
      "val Loss: 0.0774 Acc: 0.9756\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0554 Acc: 0.9810\n",
      "val Loss: 0.1248 Acc: 0.9609\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0608 Acc: 0.9782\n",
      "val Loss: 0.0824 Acc: 0.9687\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0710 Acc: 0.9757\n",
      "val Loss: 0.0417 Acc: 0.9883\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0517 Acc: 0.9808\n",
      "val Loss: 0.0632 Acc: 0.9844\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0515 Acc: 0.9833\n",
      "val Loss: 0.0663 Acc: 0.9863\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0534 Acc: 0.9822\n",
      "val Loss: 0.0717 Acc: 0.9785\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0447 Acc: 0.9839\n",
      "val Loss: 0.0452 Acc: 0.9824\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0573 Acc: 0.9802\n",
      "val Loss: 0.0619 Acc: 0.9785\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9857\n",
      "val Loss: 0.0604 Acc: 0.9844\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0525 Acc: 0.9835\n",
      "val Loss: 0.1009 Acc: 0.9765\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0596 Acc: 0.9814\n",
      "val Loss: 0.0831 Acc: 0.9853\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 0.9888\n",
      "val Loss: 0.0704 Acc: 0.9863\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0419 Acc: 0.9857\n",
      "val Loss: 0.0731 Acc: 0.9834\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0571 Acc: 0.9796\n",
      "val Loss: 0.1051 Acc: 0.9717\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0370 Acc: 0.9869\n",
      "val Loss: 0.0739 Acc: 0.9795\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0449 Acc: 0.9839\n",
      "val Loss: 0.0668 Acc: 0.9814\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.0358 Acc: 0.9890\n",
      "val Loss: 0.0691 Acc: 0.9853\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0420 Acc: 0.9855\n",
      "val Loss: 0.0998 Acc: 0.9687\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0469 Acc: 0.9847\n",
      "val Loss: 0.0869 Acc: 0.9785\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0370 Acc: 0.9876\n",
      "val Loss: 0.0527 Acc: 0.9804\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0330 Acc: 0.9894\n",
      "val Loss: 0.0814 Acc: 0.9736\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0506 Acc: 0.9825\n",
      "val Loss: 0.0593 Acc: 0.9814\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0341 Acc: 0.9886\n",
      "val Loss: 0.0847 Acc: 0.9717\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0334 Acc: 0.9892\n",
      "val Loss: 0.0776 Acc: 0.9775\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0419 Acc: 0.9853\n",
      "val Loss: 0.0926 Acc: 0.9785\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0396 Acc: 0.9869\n",
      "val Loss: 0.1224 Acc: 0.9726\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0284 Acc: 0.9902\n",
      "val Loss: 0.1584 Acc: 0.9697\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9888\n",
      "val Loss: 0.1725 Acc: 0.9560\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9898\n",
      "val Loss: 0.0908 Acc: 0.9804\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0386 Acc: 0.9871\n",
      "val Loss: 0.0924 Acc: 0.9824\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9843\n",
      "val Loss: 0.0750 Acc: 0.9853\n",
      "\n",
      "Training complete in 42m 39s\n",
      "Best val Acc: 0.988270\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/karioi\"\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "num_classes = 5\n",
    "batch_size = 32\n",
    "input_size = 224\n",
    "num_epochs = 50\n",
    "feature_extract = False\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n",
    "        transforms.RandomRotation(180),\n",
    "        transforms.RandomResizedCrop(input_size, scale=(0.6, 0.8), ratio=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.025, 0.1), ratio=(0.3, 3.3)),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_names=['resnet18','resnet34','resnet50']\n",
    "for model_name in model_names:\n",
    "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    params_to_update = model_ft.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=0.0001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "    torch.save(model_ft.state_dict(), f\"predator_small_auged_ver12_{model_name}_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b34fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
