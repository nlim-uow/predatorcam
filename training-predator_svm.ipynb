{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae066023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.9.0\n",
      "Torchvision Version:  0.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9abdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.view(inputs.shape[0],-1).to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40610831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa769728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet34\":\n",
    "        \"\"\" Resnet34\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet50\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"resnet101\":\n",
    "        \"\"\" Resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet152\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224    \n",
    "    \n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "        \n",
    "    elif model_name == \"svm\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = nn.Linear(3*224*224,num_classes) \n",
    "        input_size = 224       \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "#model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cea5715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n",
      "Params to learn:\n",
      "\t weight\n",
      "\t bias\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.6713 Acc: 0.2400\n",
      "val Loss: 1.6057 Acc: 0.2551\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.5545 Acc: 0.2939\n",
      "val Loss: 1.5468 Acc: 0.2923\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.5054 Acc: 0.3110\n",
      "val Loss: 1.5033 Acc: 0.3226\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.4751 Acc: 0.3257\n",
      "val Loss: 1.4937 Acc: 0.3216\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.4626 Acc: 0.3208\n",
      "val Loss: 1.4872 Acc: 0.3128\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.4548 Acc: 0.3278\n",
      "val Loss: 1.4812 Acc: 0.3196\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.4505 Acc: 0.3322\n",
      "val Loss: 1.4657 Acc: 0.3187\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.4324 Acc: 0.3408\n",
      "val Loss: 1.4612 Acc: 0.3275\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.4393 Acc: 0.3294\n",
      "val Loss: 1.4544 Acc: 0.3187\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.4223 Acc: 0.3390\n",
      "val Loss: 1.4411 Acc: 0.3324\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.4235 Acc: 0.3394\n",
      "val Loss: 1.4346 Acc: 0.3441\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.4174 Acc: 0.3425\n",
      "val Loss: 1.4347 Acc: 0.3392\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.4224 Acc: 0.3400\n",
      "val Loss: 1.4250 Acc: 0.3353\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.4158 Acc: 0.3378\n",
      "val Loss: 1.4200 Acc: 0.3412\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.4125 Acc: 0.3373\n",
      "val Loss: 1.4238 Acc: 0.3412\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.4154 Acc: 0.3400\n",
      "val Loss: 1.4170 Acc: 0.3500\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.4180 Acc: 0.3369\n",
      "val Loss: 1.4178 Acc: 0.3421\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.4137 Acc: 0.3412\n",
      "val Loss: 1.4315 Acc: 0.3333\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.4121 Acc: 0.3445\n",
      "val Loss: 1.4304 Acc: 0.3265\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.4110 Acc: 0.3400\n",
      "val Loss: 1.4308 Acc: 0.3324\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.4181 Acc: 0.3441\n",
      "val Loss: 1.4078 Acc: 0.3412\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.4068 Acc: 0.3488\n",
      "val Loss: 1.3995 Acc: 0.3519\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.4139 Acc: 0.3422\n",
      "val Loss: 1.4030 Acc: 0.3500\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.4094 Acc: 0.3390\n",
      "val Loss: 1.4142 Acc: 0.3324\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.4049 Acc: 0.3445\n",
      "val Loss: 1.4100 Acc: 0.3451\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.4005 Acc: 0.3475\n",
      "val Loss: 1.4101 Acc: 0.3490\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.4053 Acc: 0.3461\n",
      "val Loss: 1.4182 Acc: 0.3353\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.4032 Acc: 0.3437\n",
      "val Loss: 1.4071 Acc: 0.3548\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.3979 Acc: 0.3482\n",
      "val Loss: 1.4117 Acc: 0.3548\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.4116 Acc: 0.3400\n",
      "val Loss: 1.4021 Acc: 0.3451\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.4063 Acc: 0.3447\n",
      "val Loss: 1.4030 Acc: 0.3412\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.4113 Acc: 0.3443\n",
      "val Loss: 1.4055 Acc: 0.3412\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.4055 Acc: 0.3447\n",
      "val Loss: 1.4071 Acc: 0.3490\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.4076 Acc: 0.3384\n",
      "val Loss: 1.4002 Acc: 0.3500\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.4031 Acc: 0.3476\n",
      "val Loss: 1.4048 Acc: 0.3392\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.4017 Acc: 0.3396\n",
      "val Loss: 1.3992 Acc: 0.3480\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.4034 Acc: 0.3482\n",
      "val Loss: 1.4023 Acc: 0.3451\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.4045 Acc: 0.3482\n",
      "val Loss: 1.4069 Acc: 0.3441\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.4058 Acc: 0.3375\n",
      "val Loss: 1.4063 Acc: 0.3470\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.4125 Acc: 0.3398\n",
      "val Loss: 1.3976 Acc: 0.3460\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.4049 Acc: 0.3443\n",
      "val Loss: 1.3962 Acc: 0.3412\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.4126 Acc: 0.3380\n",
      "val Loss: 1.4053 Acc: 0.3519\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.4032 Acc: 0.3427\n",
      "val Loss: 1.3903 Acc: 0.3539\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.3970 Acc: 0.3445\n",
      "val Loss: 1.4026 Acc: 0.3460\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.3978 Acc: 0.3529\n",
      "val Loss: 1.4040 Acc: 0.3382\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.4008 Acc: 0.3471\n",
      "val Loss: 1.3907 Acc: 0.3548\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.4072 Acc: 0.3459\n",
      "val Loss: 1.3960 Acc: 0.3539\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.4079 Acc: 0.3414\n",
      "val Loss: 1.4028 Acc: 0.3607\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.4080 Acc: 0.3435\n",
      "val Loss: 1.4037 Acc: 0.3519\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.4024 Acc: 0.3469\n",
      "val Loss: 1.4014 Acc: 0.3470\n",
      "\n",
      "Training complete in 10m 41s\n",
      "Best val Acc: 0.360704\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/karioi\"\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "num_classes = 5\n",
    "batch_size = 32\n",
    "input_size = 224\n",
    "num_epochs = 50\n",
    "feature_extract = True\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n",
    "        transforms.RandomRotation(180),\n",
    "        transforms.RandomResizedCrop(input_size, scale=(0.6, 0.8), ratio=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.025, 0.1), ratio=(0.3, 3.3)),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_names=['svm']\n",
    "for model_name in model_names:\n",
    "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    params_to_update = model_ft.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=0.0000002)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "    torch.save(model_ft.state_dict(), f\"predator_small_auged_ver12_{model_name}_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434e56da-be76-465c-a382-ae8c849127f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-76046d0982e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "p=nn.Flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b9d06-a0da-4570-baf9-614131eaaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(32,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760dcd2-40df-435d-834b-0f972c5fc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training complete in 11m 2s\n",
    "Best val Acc: 0.437928\n",
    "Training complete in 10m 29s\n",
    "Best val Acc: 0.384164\n",
    "Training complete in 10m 37s\n",
    "Best val Acc: 0.418377\n",
    "Training complete in 10m 37s\n",
    "Best val Acc: 0.393939\n",
    "Training complete in 10m 25s\n",
    "Best val Acc: 0.392962\n",
    "Training complete in 10m 43s\n",
    "Best val Acc: 0.391984"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
